# tg_churn_bot.py
# Telegram-–±–æ—Ç –¥–ª—è –∞–ª—ë—Ä—Ç–æ–≤ –ø–æ –æ—Ç—Ç–æ–∫—É LMS.
# v2.2 ‚Äî autodetect(schema), robust events‚Üífeatures, UX spinner & nice errors

import os
import io
import zipfile
import traceback
from datetime import datetime, timedelta

import pandas as pd
from telegram import (
    Update,
    ReplyKeyboardMarkup,
    KeyboardButton,
)
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
    CallbackContext,
)

# ----------------------- CONFIG -----------------------
TG_TOKEN = os.getenv("TG_TOKEN", "").strip()
UPLOAD_DIR = os.getenv("DATA_DIR", "./uploads")
MODEL_PATH = os.getenv("MODEL_PATH", "").strip()  # –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ: –ø—É—Ç—å –∫ .pkl
CLEAR_ON_NEW_UPLOAD = os.getenv("CLEAR_ON_NEW_UPLOAD", "false").lower() in {"1", "true", "yes"}

DEFAULT_THRESHOLD = float(os.getenv("DEFAULT_THRESHOLD", "0.35"))
DEFAULT_TOP_N = int(os.getenv("DEFAULT_TOP_N", "20"))

os.makedirs(UPLOAD_DIR, exist_ok=True)

# ----------------------- UX: Keyboards ----------------
def make_keyboard(has_files: bool) -> ReplyKeyboardMarkup:
    """
    –ü–æ–∫–∞–∑—ã–≤–∞–µ–º '–ó–∞–ø—É—Å—Ç–∏—Ç—å /run' —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –µ—Å—Ç—å –≤–∞–ª–∏–¥–Ω—ã–µ –≤—ã–≥—Ä—É–∑–∫–∏.
    """
    row1 = []
    if has_files:
        row1.append(KeyboardButton("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å /run"))
    row1.append(KeyboardButton("üìä –°—Ç–∞—Ç—É—Å"))

    row2 = [KeyboardButton("‚öôÔ∏è –ü–æ—Ä–æ–≥ —Ä–∏—Å–∫–∞"), KeyboardButton("ü•á –¢–æ–ø-N")]
    row3 = [KeyboardButton("üßπ –û—á–∏—Å—Ç–∏—Ç—å –≤—ã–≥—Ä—É–∑–∫–∏"), KeyboardButton("üÜò –ü–æ–º–æ—â—å")]

    rows = []
    if row1:
        rows.append(row1)
    rows.append(row2)
    rows.append(row3)
    return ReplyKeyboardMarkup(rows, resize_keyboard=True)


# ----------------------- Schema detection -------------
EMAIL_SYNONYMS = ["email", "user_id", "login", "mail", "e-mail", "user"]

def _find_email_col(df: pd.DataFrame) -> str | None:
    cols = list(df.columns)
    low = {c.lower(): c for c in cols}
    for key in EMAIL_SYNONYMS:
        if key in low:
            return low[key]
    # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
    for c in cols:
        try:
            if df[c].astype(str).str.contains("@").mean() > 0.5:
                return c
        except Exception:
            pass
    return None

def _find_ts_col(df: pd.DataFrame) -> str | None:
    candidates = ["timestamp", "time", "ts", "event_time", "created_at", "last_event_at"]
    low = {c.lower(): c for c in df.columns}
    for key in candidates:
        if key in low:
            return low[key]
    # —ç–≤—Ä–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–∏–ø—É
    for c in df.columns:
        try:
            pd.to_datetime(df[c], errors="raise")
            return c
        except Exception:
            pass
    return None

def detect_schema(df: pd.DataFrame) -> str:
    cols = {c.lower() for c in df.columns}
    # —É–∂–µ –≥–æ—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    if {"email", "last_event_at", "events_28d", "quiz_avg"}.issubset(cols):
        return "features"
    # –≤–µ—Ä–æ—è—Ç–Ω—ã–π –ª–æ–≥ —Å–æ–±—ã—Ç–∏–π
    if _find_email_col(df) and _find_ts_col(df):
        return "events"
    return "unknown"

def build_features_from_events(dfs: list[pd.DataFrame]) -> pd.DataFrame:
    raw = pd.concat(dfs, ignore_index=True)

    email_col = _find_email_col(raw)
    ts_col    = _find_ts_col(raw)
    if not email_col or not ts_col:
        raise ValueError("–ù–µ –Ω–∞—à—ë–ª –∫–æ–ª–æ–Ω–∫–∏ email/timestamp –≤ —Å–æ–±—ã—Ç–∏—è—Ö.")

    raw = raw.rename(columns={email_col: "email", ts_col: "timestamp"})
    raw["timestamp"] = pd.to_datetime(raw["timestamp"], errors="coerce")
    raw = raw.dropna(subset=["email", "timestamp"])

    # —Ä–µ—Ñ–µ—Ä–µ–Ω—Å ‚Äî max(timestamp) –≤ –≤—ã–≥—Ä—É–∑–∫–µ (—É—Å—Ç–æ–π—á–∏–≤–æ –¥–ª—è —Ç–µ—Å—Ç–æ–≤/—Å—Ç–∞—Ä—ã—Ö –¥–∞–º–ø–æ–≤)
    ref_now = raw["timestamp"].max()
    win_from = ref_now - timedelta(days=28)

    last_event = raw.groupby("email")["timestamp"].max().rename("last_event_at")
    events_28d = (
        raw[raw["timestamp"].between(win_from, ref_now)]
        .groupby("email")["timestamp"].count()
        .rename("events_28d")
    )

    # –∫–≤–∏–∑—ã (–µ—Å–ª–∏ –µ—Å—Ç—å)
    evt_col = next((c for c in ["event_type", "event", "type"] if c in raw.columns), None)
    score_col = next((c for c in ["score", "quiz_score"] if c in raw.columns), None)

    if evt_col and score_col:
        quiz_mask = raw[evt_col].astype(str).str.lower().isin(["quiz", "test", "exam"])
        quiz_avg = (
            raw[quiz_mask]
            .groupby("email")[score_col].mean()
            .round(2)
            .rename("quiz_avg")
        )
    else:
        quiz_avg = pd.Series(dtype=float, name="quiz_avg")

    # –±–µ–∑–æ–ø–∞—Å–Ω–∞—è —Å–±–æ—Ä–∫–∞
    all_emails = pd.Index(sorted(raw["email"].unique()), name="email")
    out = pd.concat([last_event, events_28d, quiz_avg], axis=1).reindex(all_emails)
    out = out.reset_index()

    out["events_28d"] = out["events_28d"].fillna(0).astype(int)
    out["quiz_avg"]   = out["quiz_avg"].fillna(0)
    out["last_event_at"] = pd.to_datetime(out["last_event_at"]).dt.strftime("%Y-%m-%dT%H:%M:%S")
    return out[["email", "last_event_at", "events_28d", "quiz_avg"]]


# ----------------------- File loading -----------------
def _read_csv_bytes(b: bytes) -> pd.DataFrame:
    return pd.read_csv(io.BytesIO(b))

def _read_xlsx_bytes(b: bytes) -> list[pd.DataFrame]:
    xl = pd.ExcelFile(io.BytesIO(b))
    return [xl.parse(s) for s in xl.sheet_names]

def load_tables_from_path(path: str) -> list[pd.DataFrame]:
    """
    –ü–æ–¥–¥–µ—Ä–∂–∫–∞ CSV / XLSX / ZIP (–≤–Ω—É—Ç—Ä–∏ ‚Äî csv/xlsx).
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–æ–≤.
    """
    path_low = path.lower()
    dfs: list[pd.DataFrame] = []

    if path_low.endswith(".csv"):
        dfs.append(pd.read_csv(path))
    elif path_low.endswith((".xlsx", ".xls")):
        xl = pd.ExcelFile(path)
        for s in xl.sheet_names:
            dfs.append(xl.parse(s))
    elif path_low.endswith(".zip"):
        with zipfile.ZipFile(path, "r") as zf:
            for name in zf.namelist():
                nlow = name.lower()
                with zf.open(name) as f:
                    data = f.read()
                if nlow.endswith(".csv"):
                    dfs.append(_read_csv_bytes(data))
                elif nlow.endswith((".xlsx", ".xls")):
                    dfs.extend(_read_xlsx_bytes(data))
    else:
        raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞: {os.path.basename(path)}")

    # –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    norm = []
    for d in dfs:
        d = d.copy()
        d.columns = [str(c).strip() for c in d.columns]
        norm.append(d)
    return norm


# ----------------------- Scoring ----------------------
_model = None
def _load_model_if_any():
    global _model
    if _model is not None:
        return
    if MODEL_PATH and os.path.exists(MODEL_PATH):
        try:
            import joblib
            _model = joblib.load(MODEL_PATH)
        except Exception:
            _model = None

def _days_inactive(last_event_at: str, ref: datetime | None = None) -> int:
    try:
        dt = pd.to_datetime(last_event_at)
        ref = ref or datetime.utcnow()
        return max(0, (ref - dt.to_pydatetime()).days)
    except Exception:
        return 9999

def rule_based_score(df: pd.DataFrame) -> pd.Series:
    """
    –ê–∫–∫—É—Ä–∞—Ç–Ω—ã–π –±–µ–π–∑–ª–∞–π–Ω, –µ—Å–ª–∏ –Ω–µ—Ç –º–æ–¥–µ–ª–∏.
    p ~ –æ—Ç 0 –¥–æ 1. –£—á–∏—Ç—ã–≤–∞–µ–º:
      - –¥–Ω–∏ –±–µ–∑ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏,
      - –º–∞–ª–æ–µ —á–∏—Å–ª–æ —Å–æ–±—ã—Ç–∏–π –∑–∞ 28–¥,
      - –Ω–∏–∑–∫–∏–π —Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª –∫–≤–∏–∑–æ–≤.
    """
    ref_now = datetime.utcnow()
    days = df["last_event_at"].apply(lambda s: _days_inactive(s, ref_now))
    events = df.get("events_28d", pd.Series([0]*len(df)))
    quiz = df.get("quiz_avg", pd.Series([0]*len(df))).fillna(0)

    # –Ω–æ—Ä–º–∏—Ä–æ–≤–∫–∏ / –≤–µ—Å–∞
    p = (
        (days.clip(0, 60) / 60) * 0.6 +
        ((10 - events.clip(0, 10)) / 10) * 0.3 +
        ((100 - quiz.clip(0, 100)) / 100) * 0.1
    )
    return p.clip(0, 1)

def predict_scores(features: pd.DataFrame) -> pd.Series:
    _load_model_if_any()
    if _model is not None:
        # –æ–∂–∏–¥–∞–µ–º –ø–æ—Ä—è–¥–æ–∫: –Ω—É–∂–Ω–æ –ø–æ–¥–æ–≥–Ω–∞—Ç—å –∫ –ø—Ä–∏–∑–Ω–∞–∫–∞–º –º–æ–¥–µ–ª–∏, –µ—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—à—å pkl
        # –¥–ª—è —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ—Å—Ç–∏ ‚Äî fallback –∫ –±–µ–π–∑–ª–∞–π–Ω—É –ø—Ä–∏ –æ—à–∏–±–∫–µ
        try:
            X = features.copy()
            # –≤–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏–≤–µ–¥–µ–Ω–∏—è —Ç–∏–ø–æ–≤
            X["events_28d"] = X["events_28d"].astype(float)
            X["quiz_avg"]   = X["quiz_avg"].astype(float)
            # last_event_at ‚Üí days_inactive
            X["days_inactive"] = X["last_event_at"].apply(lambda s: _days_inactive(s))
            use_cols = [c for c in ["days_inactive", "events_28d", "quiz_avg"] if c in X.columns]
            p = pd.Series(_model.predict_proba(X[use_cols])[:, 1], index=features.index)
            return p.clip(0, 1)
        except Exception:
            pass
    return rule_based_score(features)


# ----------------------- Helpers ----------------------
def has_any_valid_upload() -> bool:
    files = [f for f in os.listdir(UPLOAD_DIR) if not f.startswith(".")]
    return len(files) > 0

def list_uploaded_paths() -> list[str]:
    paths = []
    for f in sorted(os.listdir(UPLOAD_DIR)):
        if f.startswith("."):
            continue
        paths.append(os.path.join(UPLOAD_DIR, f))
    return paths

def clear_uploads():
    for p in list_uploaded_paths():
        try:
            os.remove(p)
        except Exception:
            pass

def short_trace(exc: Exception) -> str:
    tb = traceback.format_exc(limit=4)
    return "\n".join(tb.strip().splitlines()[-4:])


# ----------------------- Handlers ---------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    has_files = has_any_valid_upload()
    await update.message.reply_text(
        "–ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç –∞–ª—ë—Ä—Ç–æ–≤ –ø–æ –æ—Ç—Ç–æ–∫—É LMS.\n"
        "–ü—Ä–∏—à–ª–∏ CSV/XLSX –≤—ã–≥—Ä—É–∑–∫–∏, —è –∏—Ö —Å–æ—Ö—Ä–∞–Ω—é.\n\n"
        "–ù–∞–∂–∏–º–∞–π –∫–Ω–æ–ø–∫–∏ –Ω–∏–∂–µ –∏–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–π –∫–æ–º–∞–Ω–¥—ã.",
        reply_markup=make_keyboard(has_files),
    )

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    txt = (
        "–ö–æ–º–∞–Ω–¥—ã –∏ –∫–Ω–æ–ø–∫–∏:\n"
        "‚Ä¢ üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å /run ‚Äî —Å–∫–æ—Ä–∏–Ω–≥ –ø–æ –ø–æ—Å–ª–µ–¥–Ω–∏–º –≤—ã–≥—Ä—É–∑–∫–∞–º\n"
        "‚Ä¢ üìä –°—Ç–∞—Ç—É—Å ‚Äî –∫–æ–Ω—Ñ–∏–≥ –∏ —Ç–µ–∫—É—â–∞—è –ø–∞–ø–∫–∞\n"
        "‚Ä¢ ‚öôÔ∏è –ü–æ—Ä–æ–≥ —Ä–∏—Å–∫–∞ ‚Äî —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å, –Ω–∞–ø—Ä–∏–º–µ—Ä 0.35\n"
        "‚Ä¢ ü•á –¢–æ–ø-N ‚Äî —Å–∫–æ–ª—å–∫–æ –≤–µ—Ä—Ö–Ω–∏—Ö –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å\n"
        "‚Ä¢ üßπ –û—á–∏—Å—Ç–∏—Ç—å –≤—ã–≥—Ä—É–∑–∫–∏ ‚Äî —É–±—Ä–∞—Ç—å –≤—Å–µ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã\n\n"
        "–§–æ—Ä–º–∞—Ç—ã –¥–∞–Ω–Ω—ã—Ö:\n"
        "A) features CSV/XLSX: email,last_event_at,events_28d,quiz_avg\n"
        "B) events CSV/XLSX/ZIP: user_id/email + timestamp + (event_type,score) ‚Äî –∞–≥—Ä–µ–≥–∏—Ä—É—é —Å–∞–º."
    )
    await update.message.reply_text(txt, reply_markup=make_keyboard(has_any_valid_upload()))

async def status_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    thresh = context.chat_data.get("threshold", DEFAULT_THRESHOLD)
    topn = context.chat_data.get("topn", DEFAULT_TOP_N)
    files = "\n".join([f"‚Ä¢ {os.path.basename(p)}" for p in list_uploaded_paths()]) or "‚Äî"
    model = MODEL_PATH or "‚Äî"
    txt = (
        f"üîß –°—Ç–∞—Ç—É—Å:\n"
        f"–ü–æ—Ä–æ–≥ —Ä–∏—Å–∫–∞: {thresh}\n–¢–æ–ø-N: {topn}\n"
        f"–ú–æ–¥–µ–ª—å: {model}\n"
        f"–ü–∞–ø–∫–∞ –≤—ã–≥—Ä—É–∑–æ–∫: {UPLOAD_DIR}\n"
        f"–§–∞–π–ª—ã:\n{files}"
    )
    await update.message.reply_text(txt, reply_markup=make_keyboard(has_any_valid_upload()))

async def set_threshold_btn(update: Update, context: CallbackContext):
    await update.message.reply_text(
        "–í–≤–µ–¥–∏ –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä 0.35):",
        reply_markup=make_keyboard(has_any_valid_upload()),
    )
    context.chat_data["await_threshold"] = True

async def set_topn_btn(update: Update, context: CallbackContext):
    await update.message.reply_text(
        "–í–≤–µ–¥–∏ –Ω–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ Top-N (–Ω–∞–ø—Ä–∏–º–µ—Ä 20):",
        reply_markup=make_keyboard(has_any_valid_upload()),
    )
    context.chat_data["await_topn"] = True

async def clean_btn(update: Update, context: CallbackContext):
    clear_uploads()
    await update.message.reply_text("üßπ –û—á–∏—â–µ–Ω–æ —Ñ–∞–π–ª–æ–≤: 1\n–ü—Ä–∏—à–ª–∏ –Ω–æ–≤—ã–µ –≤—ã–≥—Ä—É–∑–∫–∏.", reply_markup=make_keyboard(False))

async def handle_text(update: Update, context: CallbackContext):
    text = (update.message.text or "").strip()

    # –æ–∂–∏–¥–∞–Ω–∏–µ —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
    if context.chat_data.pop("await_threshold", False):
        try:
            v = float(text.replace(",", "."))
            context.chat_data["threshold"] = v
            await update.message.reply_text(f"–û–∫, –ø–æ—Ä–æ–≥ —Ä–∏—Å–∫–∞ = {v}", reply_markup=make_keyboard(has_any_valid_upload()))
        except Exception:
            await update.message.reply_text("–ù–µ –ø–æ–Ω—è–ª —á–∏—Å–ª–æ. –ü—Ä–∏–º–µ—Ä: 0.35", reply_markup=make_keyboard(has_any_valid_upload()))
        return

    if context.chat_data.pop("await_topn", False):
        try:
            v = int(text)
            context.chat_data["topn"] = v
            await update.message.reply_text(f"–û–∫, Top-N = {v}", reply_markup=make_keyboard(has_any_valid_upload()))
        except Exception:
            await update.message.reply_text("–ù–µ –ø–æ–Ω—è–ª —á–∏—Å–ª–æ. –ü—Ä–∏–º–µ—Ä: 20", reply_markup=make_keyboard(has_any_valid_upload()))
        return

    # –∫–Ω–æ–ø–∫–∏/–∫–æ–º–∞–Ω–¥—ã
    low = text.lower()
    if "–∑–∞–ø—É—Å—Ç–∏—Ç—å" in low or low.startswith("/run"):
        await run_cmd(update, context)
    elif "—Å—Ç–∞—Ç—É—Å" in low or low.startswith("/status"):
        await status_cmd(update, context)
    elif "–ø–æ—Ä–æ–≥" in low:
        await set_threshold_btn(update, context)
    elif "—Ç–æ–ø" in low:
        await set_topn_btn(update, context)
    elif "–æ—á–∏—Å—Ç" in low:
        await clean_btn(update, context)
    elif "–ø–æ–º–æ—â" in low or low.startswith("/help"):
        await help_cmd(update, context)
    else:
        await update.message.reply_text("–ù–µ –ø–æ–Ω—è–ª. –ù–∞–∂–º–∏ –∫–Ω–æ–ø–∫—É –∏–ª–∏ /help.", reply_markup=make_keyboard(has_any_valid_upload()))

async def handle_document(update: Update, context: CallbackContext):
    try:
        if CLEAR_ON_NEW_UPLOAD:
            clear_uploads()
        doc = update.message.document
        if not doc:
            await update.message.reply_text("–ü—Ä–∏—à–ª–∏ CSV/XLSX/ZIP —Ñ–∞–π–ª.")
            return
        file = await context.bot.get_file(doc.file_id)
        fn = doc.file_name or f"upload_{int(datetime.utcnow().timestamp())}"
        save_path = os.path.join(UPLOAD_DIR, fn)
        await file.download_to_drive(save_path)
        await update.message.reply_text(
            f"‚úÖ –§–∞–π–ª —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {save_path}\n"
            f"–ú–æ–∂–µ—à—å –Ω–∞–∂–∞—Ç—å ¬´–ó–∞–ø—É—Å—Ç–∏—Ç—å /run¬ª.",
            reply_markup=make_keyboard(True),
        )
    except Exception as e:
        await update.message.replyText(f"üî¥ –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}\n{short_trace(e)}", reply_markup=make_keyboard(has_any_valid_upload()))

async def run_cmd(update: Update, context: CallbackContext):
    files = list_uploaded_paths()
    if not files:
        await update.message.reply_text("–°–Ω–∞—á–∞–ª–∞ –ø—Ä–∏—à–ª–∏ –≤—ã–≥—Ä—É–∑–∫—É (CSV/XLSX/ZIP).", reply_markup=make_keyboard(False))
        return

    # —Å–ø–∏–Ω–Ω–µ—Ä
    msg = await update.message.reply_text("‚è≥ –ó–∞–ø—É—Å–∫–∞—é —Å–∫–æ—Ä–∏–Ω–≥‚Ä¶", reply_markup=make_keyboard(True))

    try:
        # —á–∏—Ç–∞–µ–º –≤—Å–µ —Ç–∞–±–ª–∏—Ü—ã
        all_dfs: list[pd.DataFrame] = []
        for p in files:
            all_dfs.extend(load_tables_from_path(p))

        # –æ–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ö–µ–º—ã –∏ –≥–æ—Ç–æ–≤–∏–º –ø—Ä–∏–∑–Ω–∞–∫–∏
        schemas = [detect_schema(df) for df in all_dfs]
        if any(k == "features" for k in schemas):
            feats = [df for df, k in zip(all_dfs, schemas) if k == "features"]
            features = pd.concat(feats, ignore_index=True)
            await context.bot.edit_message_text(
                chat_id=msg.chat_id, message_id=msg.message_id,
                text="üîé –ù–∞–π–¥–µ–Ω—ã –≥–æ—Ç–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏. –ò–¥—ë—Ç —Å–∫–æ—Ä–∏–Ω–≥‚Ä¶"
            )
        elif any(k == "events" for k in schemas):
            evts = [df for df, k in zip(all_dfs, schemas) if k == "events"]
            await context.bot.edit_message_text(
                chat_id=msg.chat_id, message_id=msg.message_id,
                text="üî® –û–±–Ω–∞—Ä—É–∂–µ–Ω –ª–æ–≥ —Å–æ–±—ã—Ç–∏–π. –°—Ç—Ä–æ—é –ø—Ä–∏–∑–Ω–∞–∫–∏‚Ä¶"
            )
            features = build_features_from_events(evts)
        else:
            await context.bot.edit_message_text(
                chat_id=msg.chat_id, message_id=msg.message_id,
                text=("üî¥ –ù–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–ª —Ñ–æ—Ä–º–∞—Ç –≤—ã–≥—Ä—É–∑–∫–∏.\n"
                      "–ù—É–∂–µ–Ω –ª–∏–±–æ features-CSV: email,last_event_at,events_28d,quiz_avg;\n"
                      "–ª–∏–±–æ events-–ª–æ–≥: email/user_id + timestamp (+event_type,score).")
            )
            return

        # —Å–∫–æ—Ä–∏–Ω–≥
        await context.bot.edit_message_text(
            chat_id=msg.chat_id, message_id=msg.message_id,
            text="ü§ñ –°—á–∏—Ç–∞—é –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏‚Ä¶"
        )
        p = predict_scores(features)
        features = features.copy()
        features["p"] = p

        # –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—ã–≤–æ–¥–∞
        threshold = context.chat_data.get("threshold", DEFAULT_THRESHOLD)
        topn = context.chat_data.get("topn", DEFAULT_TOP_N)

        risky = features.sort_values("p", ascending=False)
        top_rows = risky.head(topn)

        # —Ñ–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –≤—ã–≤–æ–¥
        alerts = []
        cnt_alerts = 0
        ref_now = datetime.utcnow()
        for _, r in top_rows.iterrows():
            email = str(r.get("email", "‚Äî"))
            prob = float(r["p"])
            days = _days_inactive(r.get("last_event_at", ""), ref_now)
            events_28 = int(r.get("events_28d", 0))
            quiz = r.get("quiz_avg", 0)
            reasons = []
            if days >= 20: reasons.append(f"–Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ {days}–¥–Ω")
            if events_28 <= 3: reasons.append(f"–º–∞–ª–æ —Å–æ–±—ã—Ç–∏–π –∑–∞ 28–¥ ({events_28})")
            if (isinstance(quiz, (int, float)) and quiz <= 60): reasons.append(f"–Ω–∏–∑–∫–∏–µ –∫–≤–∏–∑—ã (avg ~{int(quiz)})")
            line = f"{email} ‚Äî p={prob:.2f} ‚Äî " + ("; ".join(reasons) if reasons else "—Å–∏–≥–Ω–∞–ª–æ–≤ –º–∞–ª–æ")
            if prob >= threshold:
                cnt_alerts += 1
                alerts.append(line)

        head = f"üîî –í—Å–µ–≥–æ –∞–ª—ë—Ä—Ç–æ–≤: {cnt_alerts}/{len(top_rows)}"
        body = "\n".join([f"{i+1}. {s}" for i, s in enumerate(alerts)]) if alerts else "–Ω–µ—Ç"
        final = f"{head}\n{body}"
        await context.bot.edit_message_text(chat_id=msg.chat_id, message_id=msg.message_id, text=final)

    except Exception as e:
        txt = f"üî¥ –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏: {e}\n{short_trace(e)}"
        try:
            await context.bot.edit_message_text(chat_id=msg.chat_id, message_id=msg.message_id, text=txt)
        except Exception:
            await update.message.reply_text(txt, reply_markup=make_keyboard(has_any_valid_upload()))


# ----------------------- App bootstrap ----------------
def main():
    if not TG_TOKEN:
        raise RuntimeError("Set TG_TOKEN env var.")

    app = ApplicationBuilder().token(TG_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("status", status_cmd))
    app.add_handler(CommandHandler("run", run_cmd))

    # –∫–Ω–æ–ø–∫–∏
    app.add_handler(MessageHandler(filters.Regex("^‚öôÔ∏è –ü–æ—Ä–æ–≥ —Ä–∏—Å–∫–∞$"), set_threshold_btn))
    app.add_handler(MessageHandler(filters.Regex("^ü•á –¢–æ–ø-N$"), set_topn_btn))
    app.add_handler(MessageHandler(filters.Regex("^üßπ –û—á–∏—Å—Ç–∏—Ç—å –≤—ã–≥—Ä—É–∑–∫–∏$"), clean_btn))
    app.add_handler(MessageHandler(filters.Regex("^üÜò –ü–æ–º–æ—â—å$"), help_cmd))

    # –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ —Ç–µ–∫—Å—Ç
    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))

    app.run_polling(drop_pending_updates=True)

if __name__ == "__main__":
    main()

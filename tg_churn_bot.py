# tg_churn_bot.py
# Telegram-Ğ±Ğ¾Ñ‚ Ğ´Ğ»Ñ Ğ°Ğ»Ñ‘Ñ€Ñ‚Ğ¾Ğ² Ğ¿Ğ¾ Ğ¾Ñ‚Ñ‚Ğ¾ĞºÑƒ LMS.
# v2.3 â€” safe edit (fallback), autodetect(schema), robust eventsâ†’features, UX spinner & nice errors

import os
import io
import zipfile
import traceback
from datetime import datetime, timedelta

import pandas as pd
from telegram import (
    Update,
    ReplyKeyboardMarkup,
    KeyboardButton,
)
from telegram.error import BadRequest
from telegram.ext import (
    ApplicationBuilder,
    CommandHandler,
    MessageHandler,
    ContextTypes,
    filters,
    CallbackContext,
)

# ----------------------- CONFIG -----------------------
TG_TOKEN = os.getenv("TG_TOKEN", "").strip()
UPLOAD_DIR = os.getenv("DATA_DIR", "./uploads")
MODEL_PATH = os.getenv("MODEL_PATH", "").strip()  # Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾: Ğ¿ÑƒÑ‚ÑŒ Ğº .pkl
CLEAR_ON_NEW_UPLOAD = os.getenv("CLEAR_ON_NEW_UPLOAD", "false").lower() in {"1", "true", "yes"}

DEFAULT_THRESHOLD = float(os.getenv("DEFAULT_THRESHOLD", "0.35"))
DEFAULT_TOP_N = int(os.getenv("DEFAULT_TOP_N", "20"))

os.makedirs(UPLOAD_DIR, exist_ok=True)

# ----------------------- UX: Keyboards ----------------
def make_keyboard(has_files: bool) -> ReplyKeyboardMarkup:
    row1 = []
    if has_files:
        row1.append(KeyboardButton("ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ /run"))
    row1.append(KeyboardButton("ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ"))

    row2 = [KeyboardButton("âš™ï¸ ĞŸĞ¾Ñ€Ğ¾Ğ³ Ñ€Ğ¸ÑĞºĞ°"), KeyboardButton("ğŸ¥‡ Ğ¢Ğ¾Ğ¿-N")]
    row3 = [KeyboardButton("ğŸ§¹ ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ²Ñ‹Ğ³Ñ€ÑƒĞ·ĞºĞ¸"), KeyboardButton("ğŸ†˜ ĞŸĞ¾Ğ¼Ğ¾Ñ‰ÑŒ")]

    rows = []
    if row1:
        rows.append(row1)
    rows.append(row2)
    rows.append(row3)
    return ReplyKeyboardMarkup(rows, resize_keyboard=True)

# ---------- helpers: safe message edit ----------
async def safe_edit(msg, text: str):
    """Ğ ĞµĞ´Ğ°ĞºÑ‚Ğ¸Ñ€ÑƒĞµĞ¼ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ. Ğ•ÑĞ»Ğ¸ Ğ½ĞµĞ»ÑŒĞ·Ñ â€” Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ½Ğ¾Ğ²Ğ¾Ğµ, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ Ğ½Ğµ Ğ¿Ğ°Ğ´Ğ°Ñ‚ÑŒ."""
    try:
        await msg.edit_text(text)
    except BadRequest:
        try:
            await msg.chat.send_message(text)
        except Exception:
            pass

# ----------------------- Schema detection -------------
EMAIL_SYNONYMS = ["email", "user_id", "login", "mail", "e-mail", "user"]

def _find_email_col(df: pd.DataFrame) -> str | None:
    cols = list(df.columns)
    low = {c.lower(): c for c in cols}
    for key in EMAIL_SYNONYMS:
        if key in low:
            return low[key]
    for c in cols:
        try:
            if df[c].astype(str).str.contains("@").mean() > 0.5:
                return c
        except Exception:
            pass
    return None

def _find_ts_col(df: pd.DataFrame) -> str | None:
    candidates = ["timestamp", "time", "ts", "event_time", "created_at", "last_event_at"]
    low = {c.lower(): c for c in df.columns}
    for key in candidates:
        if key in low:
            return low[key]
    for c in df.columns:
        try:
            pd.to_datetime(df[c], errors="raise")
            return c
        except Exception:
            pass
    return None

def detect_schema(df: pd.DataFrame) -> str:
    cols = {c.lower() for c in df.columns}
    if {"email", "last_event_at", "events_28d", "quiz_avg"}.issubset(cols):
        return "features"
    if _find_email_col(df) and _find_ts_col(df):
        return "events"
    return "unknown"

def build_features_from_events(dfs: list[pd.DataFrame]) -> pd.DataFrame:
    raw = pd.concat(dfs, ignore_index=True)

    email_col = _find_email_col(raw)
    ts_col    = _find_ts_col(raw)
    if not email_col or not ts_col:
        raise ValueError("ĞĞµ Ğ½Ğ°ÑˆÑ‘Ğ» ĞºĞ¾Ğ»Ğ¾Ğ½ĞºĞ¸ email/timestamp Ğ² ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸ÑÑ….")

    raw = raw.rename(columns={email_col: "email", ts_col: "timestamp"})
    raw["timestamp"] = pd.to_datetime(raw["timestamp"], errors="coerce")
    raw = raw.dropna(subset=["email", "timestamp"])

    ref_now = raw["timestamp"].max()
    win_from = ref_now - timedelta(days=28)

    last_event = raw.groupby("email")["timestamp"].max().rename("last_event_at")
    events_28d = (
        raw[raw["timestamp"].between(win_from, ref_now)]
        .groupby("email")["timestamp"].count()
        .rename("events_28d")
    )

    evt_col = next((c for c in ["event_type", "event", "type"] if c in raw.columns), None)
    score_col = next((c for c in ["score", "quiz_score"] if c in raw.columns), None)

    if evt_col and score_col:
        quiz_mask = raw[evt_col].astype(str).str.lower().isin(["quiz", "test", "exam"])
        quiz_avg = (
            raw[quiz_mask]
            .groupby("email")[score_col].mean()
            .round(2)
            .rename("quiz_avg")
        )
    else:
        quiz_avg = pd.Series(dtype=float, name="quiz_avg")

    all_emails = pd.Index(sorted(raw["email"].unique()), name="email")
    out = pd.concat([last_event, events_28d, quiz_avg], axis=1).reindex(all_emails)
    out = out.reset_index()

    out["events_28d"] = out["events_28d"].fillna(0).astype(int)
    out["quiz_avg"]   = out["quiz_avg"].fillna(0)
    out["last_event_at"] = pd.to_datetime(out["last_event_at"]).dt.strftime("%Y-%m-%dT%H:%M:%S")
    return out[["email", "last_event_at", "events_28d", "quiz_avg"]]

# ----------------------- File loading -----------------
def _read_csv_bytes(b: bytes) -> pd.DataFrame:
    return pd.read_csv(io.BytesIO(b))

def _read_xlsx_bytes(b: bytes) -> list[pd.DataFrame]:
    xl = pd.ExcelFile(io.BytesIO(b))
    return [xl.parse(s) for s in xl.sheet_names]

def load_tables_from_path(path: str) -> list[pd.DataFrame]:
    path_low = path.lower()
    dfs: list[pd.DataFrame] = []

    if path_low.endswith(".csv"):
        dfs.append(pd.read_csv(path))
    elif path_low.endswith((".xlsx", ".xls")):
        xl = pd.ExcelFile(path)
        for s in xl.sheet_names:
            dfs.append(xl.parse(s))
    elif path_low.endswith(".zip"):
        with zipfile.ZipFile(path, "r") as zf:
            for name in zf.namelist():
                nlow = name.lower()
                with zf.open(name) as f:
                    data = f.read()
                if nlow.endswith(".csv"):
                    dfs.append(_read_csv_bytes(data))
                elif nlow.endswith((".xlsx", ".xls")):
                    dfs.extend(_read_xlsx_bytes(data))
    else:
        raise ValueError(f"ĞĞµĞ¸Ğ·Ğ²ĞµÑÑ‚Ğ½Ñ‹Ğ¹ Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ñ„Ğ°Ğ¹Ğ»Ğ°: {os.path.basename(path)}")

    norm = []
    for d in dfs:
        d = d.copy()
        d.columns = [str(c).strip() for c in d.columns]
        norm.append(d)
    return norm

# ----------------------- Scoring ----------------------
_model = None
def _load_model_if_any():
    global _model
    if _model is not None:
        return
    if MODEL_PATH and os.path.exists(MODEL_PATH):
        try:
            import joblib
            _model = joblib.load(MODEL_PATH)
        except Exception:
            _model = None

def _days_inactive(last_event_at: str, ref: datetime | None = None) -> int:
    try:
        dt = pd.to_datetime(last_event_at)
        ref = ref or datetime.utcnow()
        return max(0, (ref - dt.to_pydatetime()).days)
    except Exception:
        return 9999

def rule_based_score(df: pd.DataFrame) -> pd.Series:
    ref_now = datetime.utcnow()
    days = df["last_event_at"].apply(lambda s: _days_inactive(s, ref_now))
    events = df.get("events_28d", pd.Series([0]*len(df)))
    quiz = df.get("quiz_avg", pd.Series([0]*len(df))).fillna(0)

    p = (
        (days.clip(0, 60) / 60) * 0.6 +
        ((10 - events.clip(0, 10)) / 10) * 0.3 +
        ((100 - quiz.clip(0, 100)) / 100) * 0.1
    )
    return p.clip(0, 1)

def predict_scores(features: pd.DataFrame) -> pd.Series:
    _load_model_if_any()
    if _model is not None:
        try:
            X = features.copy()
            X["events_28d"] = X["events_28d"].astype(float)
            X["quiz_avg"]   = X["quiz_avg"].astype(float)
            X["days_inactive"] = X["last_event_at"].apply(lambda s: _days_inactive(s))
            use_cols = [c for c in ["days_inactive", "events_28d", "quiz_avg"] if c in X.columns]
            p = pd.Series(_model.predict_proba(X[use_cols])[:, 1], index=features.index)
            return p.clip(0, 1)
        except Exception:
            pass
    return rule_based_score(features)

# ----------------------- Misc helpers -----------------
def has_any_valid_upload() -> bool:
    files = [f for f in os.listdir(UPLOAD_DIR) if not f.startswith(".")]
    return len(files) > 0

def list_uploaded_paths() -> list[str]:
    paths = []
    for f in sorted(os.listdir(UPLOAD_DIR)):
        if f.startswith("."):
            continue
        paths.append(os.path.join(UPLOAD_DIR, f))
    return paths

def clear_uploads():
    for p in list_uploaded_paths():
        try:
            os.remove(p)
        except Exception:
            pass

def short_trace(exc: Exception) -> str:
    tb = traceback.format_exc(limit=4)
    return "\n".join(tb.strip().splitlines()[-4:])

# ----------------------- Handlers ---------------------
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    has_files = has_any_valid_upload()
    await update.message.reply_text(
        "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚! Ğ¯ Ğ±Ğ¾Ñ‚ Ğ°Ğ»Ñ‘Ñ€Ñ‚Ğ¾Ğ² Ğ¿Ğ¾ Ğ¾Ñ‚Ñ‚Ğ¾ĞºÑƒ LMS.\n"
        "ĞŸÑ€Ğ¸ÑˆĞ»Ğ¸ CSV/XLSX Ğ²Ñ‹Ğ³Ñ€ÑƒĞ·ĞºĞ¸, Ñ Ğ¸Ñ… ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ.\n\n"
        "ĞĞ°Ğ¶Ğ¸Ğ¼Ğ°Ğ¹ ĞºĞ½Ğ¾Ğ¿ĞºĞ¸ Ğ½Ğ¸Ğ¶Ğµ Ğ¸Ğ»Ğ¸ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹.",
        reply_markup=make_keyboard(has_files),
    )

async def help_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    txt = (
        "ĞšĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ¸ ĞºĞ½Ğ¾Ğ¿ĞºĞ¸:\n"
        "â€¢ ğŸš€ Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ /run â€” ÑĞºĞ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¿Ğ¾ Ğ¿Ğ¾ÑĞ»ĞµĞ´Ğ½Ğ¸Ğ¼ Ğ²Ñ‹Ğ³Ñ€ÑƒĞ·ĞºĞ°Ğ¼\n"
        "â€¢ ğŸ“Š Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ â€” ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ Ğ¸ Ñ‚ĞµĞºÑƒÑ‰Ğ°Ñ Ğ¿Ğ°Ğ¿ĞºĞ°\n"
        "â€¢ âš™ï¸ ĞŸĞ¾Ñ€Ğ¾Ğ³ Ñ€Ğ¸ÑĞºĞ° â€” ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ¸Ñ‚ÑŒ, Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ 0.35\n"
        "â€¢ ğŸ¥‡ Ğ¢Ğ¾Ğ¿-N â€” ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²ĞµÑ€Ñ…Ğ½Ğ¸Ñ… Ğ¿Ğ¾ĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ñ‚ÑŒ\n"
        "â€¢ ğŸ§¹ ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ²Ñ‹Ğ³Ñ€ÑƒĞ·ĞºĞ¸ â€” ÑƒĞ±Ñ€Ğ°Ñ‚ÑŒ Ğ²ÑĞµ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹\n\n"
        "Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…:\n"
        "A) features CSV/XLSX: email,last_event_at,events_28d,quiz_avg\n"
        "B) events CSV/XLSX/ZIP: user_id/email + timestamp + (event_type,score) â€” Ğ°Ğ³Ñ€ĞµĞ³Ğ¸Ñ€ÑƒÑ ÑĞ°Ğ¼."
    )
    await update.message.reply_text(txt, reply_markup=make_keyboard(has_any_valid_upload()))

async def status_cmd(update: Update, context: ContextTypes.DEFAULT_TYPE):
    thresh = context.chat_data.get("threshold", DEFAULT_THRESHOLD)
    topn = context.chat_data.get("topn", DEFAULT_TOP_N)
    files = "\n".join([f"â€¢ {os.path.basename(p)}" for p in list_uploaded_paths()]) or "â€”"
    model = MODEL_PATH or "â€”"
    txt = (
        f"ğŸ”§ Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ:\n"
        f"ĞŸĞ¾Ñ€Ğ¾Ğ³ Ñ€Ğ¸ÑĞºĞ°: {thresh}\nĞ¢Ğ¾Ğ¿-N: {topn}\n"
        f"ĞœĞ¾Ğ´ĞµĞ»ÑŒ: {model}\n"
        f"ĞŸĞ°Ğ¿ĞºĞ° Ğ²Ñ‹Ğ³Ñ€ÑƒĞ·Ğ¾Ğº: {UPLOAD_DIR}\n"
        f"Ğ¤Ğ°Ğ¹Ğ»Ñ‹:\n{files}"
    )
    await update.message.reply_text(txt, reply_markup=make_keyboard(has_any_valid_upload()))

async def set_threshold_btn(update: Update, context: CallbackContext):
    await update.message.reply_text(
        "Ğ’Ğ²ĞµĞ´Ğ¸ Ğ½Ğ¾Ğ²Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ñ€Ğ¾Ğ³Ğ° (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ 0.35):",
        reply_markup=make_keyboard(has_any_valid_upload()),
    )
    context.chat_data["await_threshold"] = True

async def set_topn_btn(update: Update, context: CallbackContext):
    await update.message.reply_text(
        "Ğ’Ğ²ĞµĞ´Ğ¸ Ğ½Ğ¾Ğ²Ğ¾Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ Top-N (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€ 20):",
        reply_markup=make_keyboard(has_any_valid_upload()),
    )
    context.chat_data["await_topn"] = True

async def clean_btn(update: Update, context: CallbackContext):
    clear_uploads()
    await update.message.reply_text("ğŸ§¹ ĞÑ‡Ğ¸Ñ‰ĞµĞ½Ğ¾ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ²: 1\nĞŸÑ€Ğ¸ÑˆĞ»Ğ¸ Ğ½Ğ¾Ğ²Ñ‹Ğµ Ğ²Ñ‹Ğ³Ñ€ÑƒĞ·ĞºĞ¸.", reply_markup=make_keyboard(False))

async def handle_text(update: Update, context: CallbackContext):
    text = (update.message.text or "").strip()

    if context.chat_data.pop("await_threshold", False):
        try:
            v = float(text.replace(",", "."))
            context.chat_data["threshold"] = v
            await update.message.reply_text(f"ĞĞº, Ğ¿Ğ¾Ñ€Ğ¾Ğ³ Ñ€Ğ¸ÑĞºĞ° = {v}", reply_markup=make_keyboard(has_any_valid_upload()))
        except Exception:
            await update.message.reply_text("ĞĞµ Ğ¿Ğ¾Ğ½ÑĞ» Ñ‡Ğ¸ÑĞ»Ğ¾. ĞŸÑ€Ğ¸Ğ¼ĞµÑ€: 0.35", reply_markup=make_keyboard(has_any_valid_upload()))
        return

    if context.chat_data.pop("await_topn", False):
        try:
            v = int(text)
            context.chat_data["topn"] = v
            await update.message.reply_text(f"ĞĞº, Top-N = {v}", reply_markup=make_keyboard(has_any_valid_upload()))
        except Exception:
            await update.message.reply_text("ĞĞµ Ğ¿Ğ¾Ğ½ÑĞ» Ñ‡Ğ¸ÑĞ»Ğ¾. ĞŸÑ€Ğ¸Ğ¼ĞµÑ€: 20", reply_markup=make_keyboard(has_any_valid_upload()))
        return

    low = text.lower()
    if "Ğ·Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ" in low or low.startswith("/run"):
        await run_cmd(update, context)
    elif "ÑÑ‚Ğ°Ñ‚ÑƒÑ" in low or low.startswith("/status"):
        await status_cmd(update, context)
    elif "Ğ¿Ğ¾Ñ€Ğ¾Ğ³" in low:
        await set_threshold_btn(update, context)
    elif "Ñ‚Ğ¾Ğ¿" in low:
        await set_topn_btn(update, context)
    elif "Ğ¾Ñ‡Ğ¸ÑÑ‚" in low:
        await clean_btn(update, context)
    elif "Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰" in low or low.startswith("/help"):
        await help_cmd(update, context)
    else:
        await update.message.reply_text("ĞĞµ Ğ¿Ğ¾Ğ½ÑĞ». ĞĞ°Ğ¶Ğ¼Ğ¸ ĞºĞ½Ğ¾Ğ¿ĞºÑƒ Ğ¸Ğ»Ğ¸ /help.", reply_markup=make_keyboard(has_any_valid_upload()))

async def handle_document(update: Update, context: CallbackContext):
    try:
        if CLEAR_ON_NEW_UPLOAD:
            clear_uploads()
        doc = update.message.document
        if not doc:
            await update.message.reply_text("ĞŸÑ€Ğ¸ÑˆĞ»Ğ¸ CSV/XLSX/ZIP Ñ„Ğ°Ğ¹Ğ».")
            return
        file = await context.bot.get_file(doc.file_id)
        fn = doc.file_name or f"upload_{int(datetime.utcnow().timestamp())}"
        save_path = os.path.join(UPLOAD_DIR, fn)
        await file.download_to_drive(save_path)
        await update.message.reply_text(
            f"âœ… Ğ¤Ğ°Ğ¹Ğ» ÑĞ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½: {save_path}\n"
            f"ĞœĞ¾Ğ¶ĞµÑˆÑŒ Ğ½Ğ°Ğ¶Ğ°Ñ‚ÑŒ Â«Ğ—Ğ°Ğ¿ÑƒÑÑ‚Ğ¸Ñ‚ÑŒ /runÂ».",
            reply_markup=make_keyboard(True),
        )
    except Exception as e:
        await update.message.reply_text(
            f"ğŸ”´ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ¿Ñ€Ğ¸ ÑĞ¾Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğ¸: {e}\n{short_trace(e)}",
            reply_markup=make_keyboard(has_any_valid_upload())
        )

async def run_cmd(update: Update, context: CallbackContext):
    files = list_uploaded_paths()
    if not files:
        await update.message.reply_text("Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ñ€Ğ¸ÑˆĞ»Ğ¸ Ğ²Ñ‹Ğ³Ñ€ÑƒĞ·ĞºÑƒ (CSV/XLSX/ZIP).", reply_markup=make_keyboard(False))
        return

    msg = await update.message.reply_text("â³ Ğ—Ğ°Ğ¿ÑƒÑĞºĞ°Ñ ÑĞºĞ¾Ñ€Ğ¸Ğ½Ğ³â€¦", reply_markup=make_keyboard(True))

    try:
        all_dfs: list[pd.DataFrame] = []
        for p in files:
            all_dfs.extend(load_tables_from_path(p))

        schemas = [detect_schema(df) for df in all_dfs]
        if any(k == "features" for k in schemas):
            feats = [df for df, k in zip(all_dfs, schemas) if k == "features"]
            features = pd.concat(feats, ignore_index=True)
            await safe_edit(msg, "ğŸ” ĞĞ°Ğ¹Ğ´ĞµĞ½Ñ‹ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ñ‹Ğµ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸. Ğ˜Ğ´Ñ‘Ñ‚ ÑĞºĞ¾Ñ€Ğ¸Ğ½Ğ³â€¦")
        elif any(k == "events" for k in schemas):
            evts = [df for df, k in zip(all_dfs, schemas) if k == "events"]
            await safe_edit(msg, "ğŸ”¨ ĞĞ±Ğ½Ğ°Ñ€ÑƒĞ¶ĞµĞ½ Ğ»Ğ¾Ğ³ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹. Ğ¡Ñ‚Ñ€Ğ¾Ñ Ğ¿Ñ€Ğ¸Ğ·Ğ½Ğ°ĞºĞ¸â€¦")
            features = build_features_from_events(evts)
        else:
            await safe_edit(
                msg,
                "ğŸ”´ ĞĞµ Ñ€Ğ°ÑĞ¿Ğ¾Ğ·Ğ½Ğ°Ğ» Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚ Ğ²Ñ‹Ğ³Ñ€ÑƒĞ·ĞºĞ¸.\n"
                "ĞÑƒĞ¶ĞµĞ½ Ğ»Ğ¸Ğ±Ğ¾ features-CSV: email,last_event_at,events_28d,quiz_avg;\n"
                "Ğ»Ğ¸Ğ±Ğ¾ events-Ğ»Ğ¾Ğ³: email/user_id + timestamp (+event_type,score)."
            )
            return

        await safe_edit(msg, "ğŸ¤– Ğ¡Ñ‡Ğ¸Ñ‚Ğ°Ñ Ğ²ĞµÑ€Ğ¾ÑÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸â€¦")
        p = predict_scores(features)
        features = features.copy()
        features["p"] = p

        threshold = context.chat_data.get("threshold", DEFAULT_THRESHOLD)
        topn = context.chat_data.get("topn", DEFAULT_TOP_N)

        risky = features.sort_values("p", ascending=False)
        top_rows = risky.head(topn)

        alerts = []
        cnt_alerts = 0
        ref_now = datetime.utcnow()
        for _, r in top_rows.iterrows():
            email = str(r.get("email", "â€”"))
            prob = float(r["p"])
            days = _days_inactive(r.get("last_event_at", ""), ref_now)
            events_28 = int(r.get("events_28d", 0))
            quiz = r.get("quiz_avg", 0)
            reasons = []
            if days >= 20: reasons.append(f"Ğ½ĞµÑ‚ Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾ÑÑ‚Ğ¸ {days}Ğ´Ğ½")
            if events_28 <= 3: reasons.append(f"Ğ¼Ğ°Ğ»Ğ¾ ÑĞ¾Ğ±Ñ‹Ñ‚Ğ¸Ğ¹ Ğ·Ğ° 28Ğ´ ({events_28})")
            if (isinstance(quiz, (int, float)) and quiz <= 60): reasons.append(f"Ğ½Ğ¸Ğ·ĞºĞ¸Ğµ ĞºĞ²Ğ¸Ğ·Ñ‹ (avg ~{int(quiz)})")
            line = f"{email} â€” p={prob:.2f} â€” " + ("; ".join(reasons) if reasons else "ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ğ¾Ğ² Ğ¼Ğ°Ğ»Ğ¾")
            if prob >= threshold:
                cnt_alerts += 1
                alerts.append(line)

        head = f"ğŸ”” Ğ’ÑĞµĞ³Ğ¾ Ğ°Ğ»Ñ‘Ñ€Ñ‚Ğ¾Ğ²: {cnt_alerts}/{len(top_rows)}"
        body = "\n".join([f"{i+1}. {s}" for i, s in enumerate(alerts)]) if alerts else "Ğ½ĞµÑ‚"
        final = f"{head}\n{body}"
        await safe_edit(msg, final)

    except Exception as e:
        txt = f"ğŸ”´ ĞÑˆĞ¸Ğ±ĞºĞ° Ğ²Ğ¾ Ğ²Ñ€ĞµĞ¼Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸: {e}\n{short_trace(e)}"
        await safe_edit(msg, txt)

# ----------------------- App bootstrap ----------------
def main():
    if not TG_TOKEN:
        raise RuntimeError("Set TG_TOKEN env var.")

    app = ApplicationBuilder().token(TG_TOKEN).build()

    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("help", help_cmd))
    app.add_handler(CommandHandler("status", status_cmd))
    app.add_handler(CommandHandler("run", run_cmd))

    app.add_handler(MessageHandler(filters.Regex("^âš™ï¸ ĞŸĞ¾Ñ€Ğ¾Ğ³ Ñ€Ğ¸ÑĞºĞ°$"), set_threshold_btn))
    app.add_handler(MessageHandler(filters.Regex("^ğŸ¥‡ Ğ¢Ğ¾Ğ¿-N$"), set_topn_btn))
    app.add_handler(MessageHandler(filters.Regex("^ğŸ§¹ ĞÑ‡Ğ¸ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ²Ñ‹Ğ³Ñ€ÑƒĞ·ĞºĞ¸$"), clean_btn))
    app.add_handler(MessageHandler(filters.Regex("^ğŸ†˜ ĞŸĞ¾Ğ¼Ğ¾Ñ‰ÑŒ$"), help_cmd))

    app.add_handler(MessageHandler(filters.Document.ALL, handle_document))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))

    app.run_polling(drop_pending_updates=True)

if __name__ == "__main__":
    main()
